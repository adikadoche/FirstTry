# -*- coding: utf-8 -*-
"""coref_analysis.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1grjpicqh9EHuQf3Gqqj_REAB2RGIzK1x
"""

import pickle
from colorama import Back, Style
from pip._vendor.colorama import Fore

path = "ontonotes_predictions.pickle"
with open(path, 'rb') as handle:
    data = pickle.load(handle)

FORES = [Fore.BLUE,
         Fore.CYAN,
         Fore.GREEN,
         Fore.MAGENTA,
         Fore.RED,
         Fore.YELLOW]
BACKS = [Back.LIGHTBLACK_EX,
         Back.LIGHTCYAN_EX,
         Back.LIGHTGREEN_EX,
         Back.LIGHTMAGENTA_EX,
         Back.LIGHTRED_EX,
         Back.LIGHTYELLOW_EX]
COLOR_WHEEL = FORES + [f + b for i, f in enumerate(FORES) for j, b in enumerate(BACKS) if i != j]


def coref_pprint(tokens, clusters, correct_flags=None, partial_cluster_to_color=None, complete_miss_flags=None, cluster_to_linked_entities=None):
    clusters = [tuple(tuple(m) for m in c) for c in clusters]

    if correct_flags is None:
        cluster_to_color = {c: COLOR_WHEEL[i % len(COLOR_WHEEL)] for i, c in enumerate(clusters)}
    elif partial_cluster_to_color is None:
        cluster_to_color = {c: COLOR_WHEEL[i % len(COLOR_WHEEL)] if not correct_flags[i] else Fore.LIGHTBLACK_EX for
                            i, c in enumerate(clusters)}
    else:
        cluster_to_color = {}
        unused_colors = list(COLOR_WHEEL)
        for c in partial_cluster_to_color.values():
            if c in unused_colors:
                unused_colors.remove(c)

        for i, c in enumerate(clusters):
            if correct_flags[i]:
                cluster_to_color[c] = Fore.LIGHTBLACK_EX
            elif c in partial_cluster_to_color:
                cluster_to_color[c] = partial_cluster_to_color[c]
            elif len(unused_colors) > 0:
                cluster_to_color[c] = unused_colors.pop()
            else:
                cluster_to_color[c] = COLOR_WHEEL[i % len(COLOR_WHEEL)]

    pretty_str = ''
    color_stack = []
    for i, t in enumerate(tokens):
        # find all mentions (from all clusters) that start at i
        # and sort all mentions/clusters by end
        mentions_start_at_i = []
        for c in clusters:
            for start, end in c:
                if start == i:
                    mentions_start_at_i.append((end, c))

        mentions_start_at_i = sorted(mentions_start_at_i, reverse=True)
        if mentions_start_at_i:
            for end, c in mentions_start_at_i:
                cluster_color = cluster_to_color[c]
                color_stack.append(cluster_color)

            _, c = mentions_start_at_i[-1]
            cluster_color = cluster_to_color[c]
            pretty_str += Style.RESET_ALL + Style.BRIGHT + cluster_color

        pretty_str += t + u' '

        # count how many mentions end at i
        mentions_end_at_i_count = len(list(_ for c in clusters for start, end in c if i == end))
        if mentions_end_at_i_count > 0:
            # pop them out of color stack
            color_stack = color_stack[:-mentions_end_at_i_count]
            pretty_str += Style.RESET_ALL
            if color_stack:
                pretty_str += Style.BRIGHT + color_stack[-1]

        # for c in clusters:
        #     for start, end in c:
        #         if i == end:
        #             pretty_str += Style.RESET_ALL
        #             color_stack.pop(-1)
        #             if color_stack:
        #                 pretty_str += Style.BRIGHT + color_stack[-1]

    pretty_str += Style.RESET_ALL + "\n"
    pretty_str = pretty_str.replace(' ##', '')

    # add cluster to the end
    for i, c in enumerate(clusters):
        cluster_color = cluster_to_color[c]
        mentions = [" ".join(tokens[start:end+1]).replace(' ##', '') for start, end in c]
        pretty_str += Style.BRIGHT + cluster_color + "[" + " | ".join(mentions) + "]" + Style.RESET_ALL

        if complete_miss_flags is not None and complete_miss_flags[i]:
            pretty_str += " - completely missed"

        if cluster_to_linked_entities:
            entities = cluster_to_linked_entities[i]
            if len(entities) > 0:
                pretty_str += " - {}".format(entities)

        pretty_str += "\n"

    print(pretty_str)
    return cluster_to_color


def flatten(l):
    return [item for sublist in l for item in sublist]


def match_clusters(gold, pred):
    sorted_gold = sorted([tuple(sorted(tuple(m) for m in c)) for c in gold])
    sorted_pred = sorted([tuple(sorted(tuple(m) for m in c)) for c in pred])

    gold_has_correct_pred = []
    pred_correct = [False] * len(sorted_pred)
    pred_to_most_similar_gold = [-1] * len(sorted_pred)
    pred_to_most_similar_golds_list = [[]] * len(sorted_pred)
    gold_to_most_similar_pred = [-1] * len(sorted_gold)
    gold_is_completely_missed = [False] * len(sorted_gold)

    for gold_index, gold_c in enumerate(sorted_gold):
        # find most similar cluster in pred
        most_similar_pred = None
        most_similar_pred_score = 0
        most_similar_pred_index = -1

        total_score = 0
        for i, pc in enumerate(sorted_pred):
            score = len(set(gold_c).intersection(set(pc)))
            total_score += score
            if score > most_similar_pred_score:
                most_similar_pred_score = score
                most_similar_pred = pc
                most_similar_pred_index = i

        if total_score == 0:
            gold_is_completely_missed[gold_index] = True

        is_correct = most_similar_pred == gold_c
        gold_has_correct_pred.append(is_correct)

        if most_similar_pred_index >= 0:
            pred_correct[most_similar_pred_index] |= is_correct
            gold_to_most_similar_pred[gold_index] = most_similar_pred_index
            pred_to_most_similar_golds_list[most_similar_pred_index].append(gold_index)

            if pred_to_most_similar_gold[most_similar_pred_index] == -1:
                pred_to_most_similar_gold[most_similar_pred_index] = gold_index

    return sorted_gold, gold_has_correct_pred,\
           sorted_pred, pred_correct, pred_to_most_similar_gold, pred_to_most_similar_golds_list,\
           gold_is_completely_missed, gold_to_most_similar_pred


def is_cluster_contains_linked_entities(cluster, entities_per_sentence, sentences, output_linked_entities=False):
    found_entity_in_cluster = False
    entities_found = set()
    for start, end in cluster:
        sentence_index = 0
        sentence = sentences[sentence_index]
        while start >= len(sentence):
            start -= len(sentence)
            end -= len(sentence)
            sentence_index += 1
            sentence = sentences[sentence_index]

        entities = entities_per_sentence[sentence_index]

        # calc mention in-sentences text location (without ##)
        char_start = len(' '.join(sentence[0:start]).replace(' ##', '').replace('[CLS] ', '')) + 1
        char_end = len(' '.join(sentence[0:end + 1]).replace(' ##', '').replace('[CLS] ', ''))

        text = ' '.join(sentence).replace(' ##', '').replace('[CLS] ', '')
        # print("'" + text[char_start:char_end] + "'")

        found_entity_for_current_mention = False
        for ent_start, ent_len, ent_text in entities:
            ent_end = ent_start + ent_len
            # if ent_start <= char_start < ent_end or ent_start < char_end <= ent_end:
            # if ent_start == char_start and char_end == ent_end:
            if ent_start >= char_start and ent_end <= char_end:
                # if found_entity_for_current_mention:
                #     print('Found more than 1 linked entity for a mention', )
                #     print('LINKED ENTITY: ', ent_text)
                #     print('Mention text: ', text[char_start:char_end])
                #     print(char_start, char_end, ent_start, ent_end)
                found_entity_for_current_mention = True
                entities_found.add(ent_text)

        if found_entity_for_current_mention:
            found_entity_in_cluster = True

    if output_linked_entities:
        return entities_found
    else:
        return found_entity_in_cluster






count_clusters = 0
count_mentions = 0
pronouns = {'i', 'me', 'my', 'mine', 'myself',
            'we', 'us', 'our', 'ours', 'ourselves',
            'you', 'your', 'yours', 'yourself', 'yourselves',
            'he', 'him', 'his', 'himself',
            'she', 'her', 'hers', 'herself',
            'it', 'its', 'itself',
            'they', 'them', 'their', 'theirs', 'themself', 'themselves',
            'this', 'these', 'that', 'those'}

count_pronouns_mentions = 0
count_clusters_with_pronoun_mention = 0
for key, example in data.items():
    gold, gold_correct, pred, pred_correct, pred_to_most_similar_gold, _, gold_is_completely_missed, gold_to_most_similar_pred = match_clusters(
        example["gold"], example["prediction"])

    pred_is_completely_missed = [similar_pred == -1 for similar_pred in pred_to_most_similar_gold]
    tokens = flatten(example["sentences"])
    count_clusters += len(gold)
    count_mentions += sum(len(c) for c in gold)

    for gold_cluster in gold:
        seen_pronoun = False
        for start,end in gold_cluster:
            mention = tokens[start:end+1]
            if " ".join(mention).lower() in pronouns:
                count_pronouns_mentions += 1
                seen_pronoun = True

        if seen_pronoun:
            count_clusters_with_pronoun_mention += 1


print("{} gold clusters".format(count_clusters))
print("{} gold mentions".format(count_mentions))
print("{} pronouns mentions".format(count_pronouns_mentions))
print("{} gold clusters with pronouns mentions".format(count_clusters_with_pronoun_mention))

count_missed_mentions = 0
count_missed_pronouns = 0
count_excess_mentions = 0
count_excess_pronous = 0
for key, example in data.items():
    gold, gold_correct, pred, pred_correct, pred_to_most_similar_gold, pred_to_most_similar_golds_list, gold_is_completely_missed, gold_to_most_similar_pred = match_clusters(
        example["gold"], example["prediction"])
    pred_is_completely_missed = [similar_pred == -1 for similar_pred in pred_to_most_similar_gold]
    tokens = flatten(example["sentences"])

    seen_preds = set()
    # calc gold to pred
    for i, gold_cluster in enumerate(gold):
        gold_cluster = set(gold_cluster)
        pred_idx = gold_to_most_similar_pred[i]
        matched_pred = set() if pred_idx is None or pred_idx==-1 else set(pred[pred_idx])
        if pred_idx is not None:
            seen_preds.add(pred_idx)
        diff = gold_cluster - matched_pred
        count_missed_mentions += len(diff)

        diff_text = {" ".join(tokens[start:end + 1]).lower() for start, end in diff}
        count_missed_pronouns += len(diff_text.intersection(pronouns))

        # diff = matched_pred - gold_cluster
        # count_excess_mentions += len(diff)
        # diff_text = {" ".join(tokens[start:end + 1]).lower() for start, end in diff}
        # count_excess_pronous += len(diff_text.intersection(pronouns))


    for i, pred_cluster, in enumerate(pred):
        pred_cluster = set(pred_cluster)
        gold_idx_list = pred_to_most_similar_golds_list[i]

        if len(gold_idx_list) == 0:
            count_excess_mentions += len(pred_cluster)
        else:
            gold_idx = max(gold_idx_list, key=lambda idx: len(set(gold[idx]).intersection(pred_cluster)))

            matched_gold = set(gold[gold_idx])
            diff = pred_cluster - matched_gold
            count_excess_mentions += len(diff)

            diff = {" ".join(tokens[start:end + 1]).lower() for start, end in diff}
            count_excess_pronous += len(diff.intersection(pronouns))




print("{} missed mentions".format(count_missed_mentions))
print("{} missed pronouns".format(count_missed_pronouns))
print("{}% missed pronouns".format(1. * count_missed_pronouns / count_missed_mentions * 100))
print("{} excess mentions".format(count_excess_mentions))
print("{} excess pronouns".format(count_excess_pronous))
print("{}% excess pronouns".format(1. * count_excess_pronous / count_excess_mentions * 100))

#

entities_per_example = pickle.load(open("dev_entities_per_example.p", "rb"))

for (key, example), i in zip(data.items(), range(35)):
    entities_per_sentence = entities_per_example[example['example_num']]

    # if key != "bc/cctv/00/cctv_0005_4":
    #     continue

    gold, gold_correct, pred, pred_correct, pred_to_most_similar_gold, _, gold_is_completely_missed, _ = match_clusters(example["gold"], example["prediction"])
    gold_clusters_to_entities = [is_cluster_contains_linked_entities(c, entities_per_sentence, example['sentences'], True) for c in gold]
    predicted_clusters_to_entities = [is_cluster_contains_linked_entities(c, entities_per_sentence, example['sentences'], True) for c in pred]

    if not (all(gold_correct) and all(pred_correct)):
        tokens = flatten(example["sentences"])
        print("EXAMPLE #{}, KEY:{}".format(i, key))
        print("GOLD CLUSTERS:")
        gold_cluster_to_color = coref_pprint(tokens, gold, gold_correct, complete_miss_flags=gold_is_completely_missed, cluster_to_linked_entities=gold_clusters_to_entities)

        pred_cluster_to_color = {}
        for pred_i, similar_gold_i in enumerate(pred_to_most_similar_gold):
            if similar_gold_i >= 0 and not gold_correct[similar_gold_i]:
                similar_color = gold_cluster_to_color[gold[similar_gold_i]]
                pred_cluster_to_color[pred[pred_i]] = similar_color

        print("PREDICTED CLUSTERS:")
        complete_miss_flags = [similar_pred == -1 for similar_pred in pred_to_most_similar_gold]
        coref_pprint(tokens, pred, pred_correct, pred_cluster_to_color, complete_miss_flags, cluster_to_linked_entities=predicted_clusters_to_entities)

        entities_set = set((e for sent_ent in entities_per_sentence for (_,_,e) in sent_ent))
        print("LINKED ENTITIES SET: ", entities_set)

        print('===========================================================================================================================================================================================================================')


